## README
ì„¤ì¹˜ëŠ” garmentpile github ê·¸ëŒ€ë¡œ ì§„í–‰. ê·¸ëŒ€ë¡œ ì‹¤í–‰í•˜ë©´ physicsë“± ì•ˆë˜ëŠ” ë¶€ë¶„ìˆì–´ì„œ ë§ì¶°ë‘ .
issac-sim 2023.1.1 ì‚¬ìš© í•„

ê° ì…€ ìŠ¤í¬ë¦½íŠ¸ í™•ì¸,
random_flag: random pick, random place -> í•™ìŠµí•  ë•Œ 
model_path: eval í•  ë•Œ
rgb_flag: rgb ì €ì¥
gif_flag: gif ì €ì¥
TARGET_DIR : ì €ì¥ ìœ„ì¹˜ ì„¤ì •
collect_epoch: ì €ì¥ scene ê°œìˆ˜

/.local/share/ov/pkg/isaac-sim-2023.1.1/python.sh ë¡œ issac-sim ì‹¤í–‰í•´ì•¼ë¨. 
```bash
# washmachine
bash Env_Data_Collection/auto_washmachine_retrieve.sh

# basket
bash Env_Data_Collection/auto_basket_retrieve.sh
```
ì €ì¥ì€ rgb, gif, pcd ì €ì¥ -> affordance í•™ìŠµì— ì‚¬ìš©ê°€ëŠ¥
- ì €ìí•œí…Œ ë¬¼ì–´ë´¤ëŠ”ë° we use about 6 RTX 4090 for data collection, and run 2 process on each GPU. It takes about 5 days to get retrieval data. ë¼ê³  í•¨.
- ë°°ê²½ ì§€ìš°ê³ , ë¡œë´‡ì´ë‘ garmentë¥¼ í•œ issac-simì—ì„œ ë©€í‹°ë¡œ ë¶ˆëŸ¬ì˜¤ê²Œ ì½”ë“œ ìˆ˜ì • í•  ìˆ˜ ìˆì„ ë“¯í•¨.
- ë°ì´í„° ëª¨ì„ ë•Œ Env_Data_Collection/*.py ì—ì„œ headless
  '''simulation_app = SimulationApp({"headless": False})''' 

  
### ê° Env_Data_collection/basket, washmachin_retrive.py ë¡œì§,
3060ì—ì„œ vram ì• ë§¤í•¨ + ì†ë„ ì¦ê°€ë¥¼ ìœ„í•´ í˜„ì¬ basket, wm ì—ì„œ ë°°ê²½ ë¶ˆëŸ¬ì˜¤ëŠ” ë¶€ë¶„ ì£¼ì„ ì²˜ë¦¬. 


- garment_into_machine()
ì¤‘ë ¥ ë°©í–¥ì„ ì‹œê°„ì— ë”°ë¼ ë°”ê¿”(x,z ì„±ë¶„ ì¡°ì ˆ) ì˜·ì´ ë“œëŸ¼ ì•ˆìœ¼ë¡œ í˜ëŸ¬ ë“¤ì–´ê°€ê²Œ í•¨. ìˆ˜ë°± ìŠ¤í… simulation_app.update()ë¡œ ì‹œë®¬ë ˆì´ì…˜ ì§„í–‰ í›„ ë‹¤ì‹œ í‘œì¤€ ì¤‘ë ¥ìœ¼ë¡œ ë³µê·€.
- remove_conveyor_belt()
ì»¨ë² ì´ì–´ í”„ë¦¼ ì‚­ì œ, ë¬¸ ìœ„ì¹˜ ìˆ˜ì •, í•œ ìŠ¤í… ë Œë”.
- create_attach_block() / set_attach_to_garment()
ê·¸ë¦¬í¼ ëì— ë¶™ì„ AttachmentBlock (<< garmentlabì€ pointë¡œ garment êµ¬í˜„í•´ì„œ ì—†ìœ¼ë©´ pick ì˜ ì•ˆë¨) ìƒì„± ë° ì¶©ëŒ ê·¸ë£¹ ê°±ì‹  â†’ íŠ¹ì • 3D ìœ„ì¹˜ë¡œ ì´ë™í•´ ì˜ë¥˜ì— â€œë¶€ì°©â€ ì²˜ë¦¬.
- get_point_cloud_data()
ëª‡ ìŠ¤í… ë Œë” í›„ Point_Cloud_Cameraë¡œ point cloud + colors íšë“. ì›í•˜ë©´ PLYë¡œ ì €ì¥.
- pick_point(random=True)
- ëœë¤/ëª¨ë¸ ê¸°ë°˜ìœ¼ë¡œ í”½ ì  ê²°ì •.
- ëª¨ë¸ ê¸°ë°˜ì¼ ë•Œ ì¶œë ¥ ë¶„í¬ë¥¼ ê²€ì‚¬í•´ â€œstir(íœ˜ì “ê¸°)â€ê°€ í•„ìš”í•˜ë©´ stir()ë¡œ ì§„ì….
- ì„ íƒëœ ì ì— attach ë¸”ë¡ ë¶€ì°© í›„ í”½ í¬ì¸íŠ¸ ë°˜í™˜.
- stir(...)
	1.	í¬ì¸íŠ¸í´ë¼ìš°ë“œ ì·¨ë“ â†’
	2.	pick_point(random=False)ë¡œ í›„ë³´ ê²°ì • â†’
	3.	ìŠ¤ë ˆë“œë¡œ ë°”ë‹¥ ì ‘ì´‰ íŒì • ì‹œì‘ â†’
	4.	franka.fetch_garment_from_washing_machine(...) ì‹¤í–‰ â†’
	5.	ê·¸ë¦¬í¼ ì˜¤í”ˆ/ë¶€ì°© í•´ì œ â†’
	6.	ì˜ë¥˜ í˜„ì¬ í¬ì¦ˆ ì¸¡ì • â†’ **ì„±ê³µ/ì‹¤íŒ¨ íŒì •(wm_judge_final_poses)**ìœ¼ë¡œ ë‚¨ì€ ì˜ë¥˜ ì¸ë±ì‹± ê°±ì‹ .
- ëª¨ë“  ì˜ë¥˜ ì²˜ë¦¬ í›„ self.point_cloud is Noneì´ë©´ ì„±ê³µ ë©”ì‹œì§€ ì°ê³  simulation_app.close() (ì—¬ê¸° break/returnì´ ì—†ì–´ ì´í›„ ì½”ë“œê°€ ê³„ì† ëŒ ìˆ˜ ìˆëŠ” ì ì€ ê°œì„  í¬ì¸íŠ¸).

ì—”íŠ¸ë¦¬í¬ì¸íŠ¸(if __name__ == "__main__":)
	1.	env = washmachineEnv()ë¡œ ìœ„ asset(garment)/ëª¨ë¸ ì „ë¶€ ë¡œë“œ.
	2.	Frankaë¥¼ ì ì‹œ ë¹„ê°€ì‹œí™”, env.world.reset(), ë‘ ì¹´ë©”ë¼ initialize().
	3.	ì˜ë¥˜ ìœ ì… ì‹œí€€ìŠ¤: garment_into_machine().
	4.	ì˜ë¥˜ ë¬¼ì„± íŠœë‹: ë§ˆì°°/ì ‘ì°© ìŠ¤ì¼€ì¼ ì¡°ì •.
	5.	ì»¨ë² ì´ì–´ ì œê±° â†’ ë¶€ì°© ë¸”ë¡ ìƒì„±/ì„¸íŒ….
	6.	ë³¸ ë£¨í”„: pick_multiple_times()ë¡œ ë°˜ë³µ í”½Â·í”Œâ†’ì„±ê³µì—¬ë¶€ ê¸°ë¡.
	7.	ëª‡ ìŠ¤í… ë” ì§„í–‰ í›„ ì‹œë®¬ë ˆì´í„° ì¢…ë£Œ.

flow
- Point_Cloud_Camera â†’ point_cloud (NÃ—3)
- ëª¨ë¸ 3ì¢…:
- Retrieve: ì§‘ê¸° ë‚œì´ë„/ìƒíƒœ í‰ê°€ (stir íŒë‹¨ ë³´ì¡°)
- Pick: point_cloudì—ì„œ í”½ ì¸ë±ìŠ¤ ì‚°ì¶œ
- Place: pick + í˜„ì¬ ì êµ°ì„ ì…ë ¥í•´ í”Œë ˆì´ìŠ¤ ìœ„ì¹˜ ì‚°ì¶œ
- Franka ë˜í¼ê°€ í•´ë‹¹ ìœ„ì¹˜ë¡œ ê²½ë¡œê³„íš/ì‹¤í–‰.
- íŒì •: wm_judge_final_posesë¡œ ì„±ê³µ/ì‹¤íŒ¨ ë¡œê¹… ë° ë‹¤ìŒ ë°˜ë³µ ì—¬ë¶€ ê²°ì •.



<h2 align="center">
  <b><tt>GarmentPile</tt>: <br>
  Point-Level Visual Affordance Guided Retrieval and Adaptation for Cluttered Garments Manipulation</b>
</h2>

<div align="center" margin-bottom="6em">
<b>CVPR 2025</b>
</div>

<br>

<div align="center">
    <a href="https://arxiv.org/pdf/2503.09243" target="_blank">
    <img src="https://img.shields.io/badge/Paper-arXiv-green" alt="Paper arXiv"></a>
    <a href="https://garmentpile.github.io/" target="_blank">
    <img src="https://img.shields.io/badge/Page-GarmentPile-red" alt="Project Page"/></a>
    <a href="https://github.com/AlwaySleepy/Garment-Pile" target="_blank">
    <img src="https://img.shields.io/badge/Code-Github-blue" alt="Github Code"/></a>
</div>

<br>

![teaser](Repo_Image/Teaser.jpg)

<p align="center" margin-bottom="20em">
<b>Garment-Pile Simulation Scene</b>
</p>

<p align="center">
  <img src="./Repo_Image/wm.jpg" alt="Image 1" width="30%" />
  <img src="./Repo_Image/sofa.jpg" alt="Image 2" width="30%" />
  <img src="./Repo_Image/basket.jpg" alt="Image 3" width="30%" />
</p>



## Get Started

### 1. Install Isaac Sim 2023.1.1
   Our Project is built upon Isaac Sim 2023.1.1. Please refer to the [official guideline](https://docs.isaacsim.omniverse.nvidia.com/latest/installation/download.html) to download it.

   After Download, please move the file into path '~/.local/share/ov/pkg/' and rename the file to be 'isaac-sim-2023.1.1' to adapt the path configuration of the repo.

   There are some modification need to be done in Isaac Sim's meta-file. Please refer to this [document](https://github.com/AlwaySleepy/Garment-Pile/blob/main/BUG_FIX.md).

### 2. Repo Preparation

- Clone the repo frist.

```
git clone https://github.com/AlwaySleepy/Garment-Pile.git
```

- Download *Garment* Assets

Here we use *Garment* Assets from GarmentLab. Please refer to [Google_Drive_link](https://drive.google.com/drive/folders/1EWH9zYQfBa96Z4JyimvUSBYOyW615JSg) to download **Garment** folder and unzip it to 'Assets/'.

### 3. Environment Preparation

- **Isaac Sim Env** Preparation

For convenience, we recommend to provide an alias for the python.sh file in Isaac Sim 2023.1.1.
```bash
# 1. open .bashrc file
sudo vim ~/.bashrc

# 2. add following part to the end of the file
alias isaac_pile=~/.local/share/ov/pkg/isaac-sim-2023.1.1/python.sh

# 3. save file and exit.

# 4. refresh for file configuration to take effect.
source ~/.bashrc
```

Install necessary packages into Isaac Sim Env.

```bash
isaac_pile -m pip install termcolor plyfile
```

- **Model Training Env** Preparation

create new conda environment

``` bash
conda create -n garmentpile python=3.10
```

Install necessary packages into Model Training Env.

``` bash
conda activate garmentpile

# CUDA version should be 11.8 or less, but no 12.X
pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu118

pip install -r requirements.txt
```

### 4. Repo Structure Explanation

    ğŸ“‚ ProjectRoot
        # VS Code Configuration Files
    â”œâ”€â”€ ğŸ“ .vscode
        # Assets used in Isaac Sim
    â”œâ”€â”€ ğŸ“ Assets
        # Isaac Sim Env Configuration, including Camera, Robot, Garment, etc.
    â”œâ”€â”€ ğŸ“ Env_Config
        # Used for train_data collection
    â”œâ”€â”€ ğŸ“ Env_Data_Collection
        # standlone environment with pre-trained model
    â”œâ”€â”€ ğŸ“ Env_Eval
        # Used for fintuning model
    â”œâ”€â”€ ğŸ“ Env_Finetune
        # Model training code
    â”œâ”€â”€ ğŸ“ Model_Train
        # repo images
    â”œâ”€â”€ ğŸ“ Repo_Image

## StandAlone Env

In our project, we provide three garment-pile scenes: **washingmachine**, **sofa**, **basket**.

You can directly run the three environment based on the file in *'Env_Eval'* folder.

The retrieve, pick, place procedure all rely on pre_trained model.

**[ATTENTION!]**
**If you find failure of assets loading in simulation, please enter "Env_Config / Config / xx_config.py" to check assets loading path.**

```bash
# washmachine
isaac_pile Env_Eval/washmachine.py

# sofa
isaac_pile Env_Eval/sofa.py

# basket
isaac_pile Env_Eval/basket.py
```

## Data Collection

Run the following command to generate retrieval data:

```bash
# washmachine
bash Env_Data_Collection/auto_washmachine_retrieve.sh

# sofa
bash Env_Data_Collection/auto_sofa_retrieve.sh

# basket
bash Env_Data_Collection/auto_basket_retrieve.sh
```

Run the following command to generate stir data:

```bash
# washmachine
bash Env_Data_Collection/auto_washmachine_stir.sh

# sofa
bash Env_Data_Collection/auto_sofa_stir.sh

# basket
bash Env_Data_Collection/auto_basket_stir.sh
```

There are some flags you can define manually in .sh file. Please check .sh file for more information. (such as, rgb_flag, random_flag, etc.)

## Model Training

Training Data are all collected in 'Data' file.

```bash
# activate conda env
conda activate garmentpile

# run any .py file in 'Model_Train' folder. remember to login in wandb
# e.g.
python Model_Train/WM_Model_train.py
```

## Finetune

We provide washmachine place model finetune code as example in 'Env_Finetune' folder.

you can run the .sh file directly to see finetune procedure.

## Citation and Reference

If you find this paper useful, please consider staring ğŸŒŸ this repo and citing ğŸ“‘ our paper:

```
@InProceedings{Wu_2025_CVPR,
      author    = {Wu, Ruihai and Zhu, Ziyu and Wang, Yuran and Chen, Yue and Wang, Jiarui and Dong, Hao},
      title     = {Point-Level Visual Affordance Guided Retrieval and Adaptation for Cluttered Garments Manipulation},
      booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
      year      = {2025},
  }
```
